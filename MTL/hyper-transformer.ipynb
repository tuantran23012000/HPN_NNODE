{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f6ef070e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.004538,
     "end_time": "2024-05-16T16:12:48.468962",
     "exception": false,
     "start_time": "2024-05-16T16:12:48.464424",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab1c140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T16:12:48.478948Z",
     "iopub.status.busy": "2024-05-16T16:12:48.478213Z",
     "iopub.status.idle": "2024-05-16T16:13:47.248456Z",
     "shell.execute_reply": "2024-05-16T16:13:47.247489Z"
    },
    "papermill": {
     "duration": 58.778024,
     "end_time": "2024-05-16T16:13:47.251051",
     "exception": false,
     "start_time": "2024-05-16T16:12:48.473027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cvxopt\r\n",
      "  Downloading cvxopt-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: cvxopt\r\n",
      "Successfully installed cvxopt-1.3.2\r\n",
      "Collecting cvxpy\r\n",
      "  Downloading cvxpy-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting osqp>=0.6.2 (from cvxpy)\r\n",
      "  Downloading osqp-0.6.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.0/299.0 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: ecos>=2 in /opt/conda/lib/python3.10/site-packages (from cvxpy) (2.0.12)\r\n",
      "Collecting clarabel>=0.5.0 (from cvxpy)\r\n",
      "  Downloading clarabel-0.7.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting scs>=3.2.4.post1 (from cvxpy)\r\n",
      "  Downloading scs-3.2.4.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.10/site-packages (from cvxpy) (1.23.5)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from cvxpy) (1.11.2)\r\n",
      "Collecting qdldl (from osqp>=0.6.2->cvxpy)\r\n",
      "  Downloading qdldl-0.1.7.post2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scs, qdldl, clarabel, osqp, cvxpy\r\n",
      "Successfully installed clarabel-0.7.1 cvxpy-1.5.1 osqp-0.6.5 qdldl-0.1.7.post2 scs-3.2.4.post1\r\n",
      "Collecting pymoo==0.5.0\r\n",
      "  Downloading pymoo-0.5.0.tar.gz (706 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.4/706.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.10/site-packages (from pymoo==0.5.0) (1.23.5)\r\n",
      "Requirement already satisfied: scipy>=1.1 in /opt/conda/lib/python3.10/site-packages (from pymoo==0.5.0) (1.11.2)\r\n",
      "Requirement already satisfied: matplotlib>=3 in /opt/conda/lib/python3.10/site-packages (from pymoo==0.5.0) (3.7.2)\r\n",
      "Collecting autograd>=1.3 (from pymoo==0.5.0)\r\n",
      "  Downloading autograd-1.6.2-py3-none-any.whl (49 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting cma==2.7 (from pymoo==0.5.0)\r\n",
      "  Downloading cma-2.7.0-py2.py3-none-any.whl (239 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.1/239.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: future>=0.15.2 in /opt/conda/lib/python3.10/site-packages (from autograd>=1.3->pymoo==0.5.0) (0.18.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->pymoo==0.5.0) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->pymoo==0.5.0) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->pymoo==0.5.0) (4.40.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->pymoo==0.5.0) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->pymoo==0.5.0) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->pymoo==0.5.0) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->pymoo==0.5.0) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3->pymoo==0.5.0) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo==0.5.0) (1.16.0)\r\n",
      "Building wheels for collected packages: pymoo\r\n",
      "  Building wheel for pymoo (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pymoo: filename=pymoo-0.5.0-cp310-cp310-linux_x86_64.whl size=1189775 sha256=0f18a3a312ee2cc180d4c6ef01a229c5cdaeac0405db6b326fb288b4ab90cd4b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/81/54/0ea5fd29acdfbbe43fe364b85c8a2d876a4aec07f34cf26dbc\r\n",
      "Successfully built pymoo\r\n",
      "Installing collected packages: cma, autograd, pymoo\r\n",
      "Successfully installed autograd-1.6.2 cma-2.7.0 pymoo-0.5.0\r\n"
     ]
    }
   ],
   "source": [
    "! pip install cvxopt\n",
    "! pip install cvxpy\n",
    "! pip install -U pymoo==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db8e34f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T16:13:47.268410Z",
     "iopub.status.busy": "2024-05-16T16:13:47.268068Z",
     "iopub.status.idle": "2024-05-16T16:13:52.129061Z",
     "shell.execute_reply": "2024-05-16T16:13:52.128349Z"
    },
    "papermill": {
     "duration": 4.871868,
     "end_time": "2024-05-16T16:13:52.130995",
     "exception": false,
     "start_time": "2024-05-16T16:13:47.259127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) May 16 04:13:52 PM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Version of ortools (9.4.1874) is too old. Expected >= 9.5.0.')\n",
      "(CVXPY) May 16 04:13:52 PM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Version of ortools (9.4.1874) is too old. Expected >= 9.7.0.')\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import trange\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/kaggle/input/hyper-trans/Hyper_trans/MTL/experiments/Multi_task/MultiMNIST\")\n",
    "print(os.getcwd())\n",
    "from metrics import hypervolumn\n",
    "from data import Dataset\n",
    "from models.hyper_mlp import (\n",
    "    LeNetHyper,\n",
    "    LeNetTarget,\n",
    ")\n",
    "from models.hyper_trans import (\n",
    "    LeNetHyper_trans,\n",
    "    LeNetTarget_trans,\n",
    ")\n",
    "from utils import (\n",
    "    circle_points,\n",
    "    count_parameters,\n",
    "    set_logger,\n",
    "    set_seed,\n",
    ")\n",
    "from solver import EPOSolver, LinearScalarizationSolver, ChebyshevBasedSolver, UtilityBasedSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15e4ca2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T16:13:52.149490Z",
     "iopub.status.busy": "2024-05-16T16:13:52.149095Z",
     "iopub.status.idle": "2024-05-16T16:13:52.208840Z",
     "shell.execute_reply": "2024-05-16T16:13:52.208084Z"
    },
    "papermill": {
     "duration": 0.071492,
     "end_time": "2024-05-16T16:13:52.210912",
     "exception": false,
     "start_time": "2024-05-16T16:13:52.139420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "import math\n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.attention = ScaleDotProductAttention()\n",
    "        self.w_q = nn.Linear(d_model, self.n_head)\n",
    "        self.w_k = nn.Linear(d_model, self.n_head)\n",
    "        self.w_v = nn.Linear(d_model, self.n_head)\n",
    "        self.w_concat = nn.Linear(self.n_head, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # 1. dot product with weight matrices\n",
    "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
    "\n",
    "        # 2. split tensor by number of heads\n",
    "        q, k, v = self.split(q), self.split(k), self.split(v)\n",
    "\n",
    "        # 3. do scale dot product to compute similarity\n",
    "        out, attention = self.attention(q, k, v, mask=mask)\n",
    "        \n",
    "        # 4. concat and pass to linear layer\n",
    "        out = self.concat(out)\n",
    "        out = self.w_concat(out)\n",
    "\n",
    "        # 5. visualize attention map\n",
    "        # TODO : we should implement visualization\n",
    "\n",
    "        return out\n",
    "\n",
    "    def split(self, tensor):\n",
    "        \"\"\"\n",
    "        split tensor by number of head\n",
    "\n",
    "        :param tensor: [batch_size, length, d_model]\n",
    "        :return: [batch_size, head, length, d_tensor]\n",
    "        \"\"\"\n",
    "        batch_size, length, d_model = tensor.size()\n",
    "\n",
    "        d_tensor = d_model // self.n_head\n",
    "        tensor = tensor.view(batch_size, length, self.n_head, d_tensor).transpose(1, 2)\n",
    "        # it is similar with group convolution (split by number of heads)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def concat(self, tensor):\n",
    "        \"\"\"\n",
    "        inverse function of self.split(tensor : torch.Tensor)\n",
    "\n",
    "        :param tensor: [batch_size, head, length, d_tensor]\n",
    "        :return: [batch_size, length, d_model]\n",
    "        \"\"\"\n",
    "        batch_size, head, length, d_tensor = tensor.size()\n",
    "        d_model = head * d_tensor\n",
    "\n",
    "        tensor = tensor.transpose(1, 2).contiguous().view(batch_size, length, d_model)\n",
    "        return tensor\n",
    "class ScaleDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    compute scale dot product attention\n",
    "\n",
    "    Query : given sentence that we focused on (decoder)\n",
    "    Key : every sentence to check relationship with Qeury(encoder)\n",
    "    Value : every sentence same with Key (encoder)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ScaleDotProductAttention, self).__init__()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None, e=1e-12):\n",
    "        # input is 4 dimension tensor\n",
    "        # [batch_size, head, length, d_tensor]\n",
    "        batch_size, head, length, d_tensor = k.size()\n",
    "\n",
    "        # 1. dot product Query with Key^T to compute similarity\n",
    "        k_t = k.transpose(2, 3)  # transpose\n",
    "        score = (q @ k_t) / math.sqrt(d_tensor)  # scaled dot product\n",
    "\n",
    "        # 2. apply masking (opt)\n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(mask == 0, -10000)\n",
    "\n",
    "        # 3. pass them softmax to make [0, 1] range\n",
    "        score = self.softmax(score)\n",
    "\n",
    "        # 4. multiply with Value\n",
    "        v = score @ v\n",
    "\n",
    "        return v, score\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-12):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, unbiased=False, keepdim=True)\n",
    "        # '-1' means last dimension. \n",
    "\n",
    "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        out = self.gamma * out + self.beta\n",
    "        return out\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, num_heads, ray_hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.ray_hidden_dim = ray_hidden_dim\n",
    "        self.multi_head_attention = nn.MultiheadAttention(embed_dim=self.ray_hidden_dim, num_heads=self.num_heads)\n",
    "        self.ffn1 = nn.Linear(self.ray_hidden_dim, self.ray_hidden_dim)\n",
    "        self.ffn2 = nn.Linear(self.ray_hidden_dim, self.ray_hidden_dim)\n",
    "    def forward(self, x):\n",
    "        x_ = x\n",
    "        x = x.unsqueeze(1)\n",
    "        x,_ = self.multi_head_attention(x,x,x)\n",
    "        x = x.squeeze(1)\n",
    "        x = x + x_\n",
    "        x_ = x\n",
    "        x = self.ffn1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.ffn2(x)\n",
    "        x = x + x_\n",
    "        return x\n",
    "class Encode(nn.Module):\n",
    "    def __init__(self, n_tasks, ray_hidden_dim):\n",
    "        super(Encode, self).__init__()\n",
    "        self.n_tasks = n_tasks\n",
    "        self.ray_hidden_dim = ray_hidden_dim\n",
    "        if self.n_tasks == 2:\n",
    "            self.embedding_layer1 =  nn.Sequential(nn.Linear(1, self.ray_hidden_dim),nn.ReLU(inplace=True))\n",
    "            self.embedding_layer2 =  nn.Sequential(nn.Linear(1, self.ray_hidden_dim),nn.ReLU(inplace=True))\n",
    "        else:\n",
    "            self.embedding_layer1 =  nn.Sequential(nn.Linear(1, self.ray_hidden_dim),nn.ReLU(inplace=True))\n",
    "            self.embedding_layer2 =  nn.Sequential(nn.Linear(1, self.ray_hidden_dim),nn.ReLU(inplace=True))\n",
    "            self.embedding_layer3 =  nn.Sequential(nn.Linear(1, self.ray_hidden_dim),nn.ReLU(inplace=True))\n",
    "    def forward(self, ray):\n",
    "        if ray.shape[0] == 2:\n",
    "            x = torch.stack((self.embedding_layer1(ray[0].unsqueeze(0)),self.embedding_layer2(ray[1].unsqueeze(0))))\n",
    "        else:\n",
    "            x = torch.stack((self.embedding_layer1(ray[0].unsqueeze(0)),self.embedding_layer2(ray[1].unsqueeze(0)),self.embedding_layer3(ray[2].unsqueeze(0))))\n",
    "        return x\n",
    "class Decode(nn.Module):\n",
    "    def __init__(self, out_dim,n_tasks):\n",
    "        super(Decode, self).__init__()\n",
    "        self.out_dim = out_dim\n",
    "        self.out_task = nn.Linear(n_tasks, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.out_task(x)\n",
    "        return x\n",
    "# class Hyper_trans3(nn.Module):\n",
    "#       \"Hypernetwork\"\n",
    "\n",
    "#       def __init__(self, ray_hidden_dim=100, out_dim = 2,n_tasks=2,num_hidden_layer=2,last_activation='relu'):\n",
    "#             super().__init__()\n",
    "#             self.out_dim = out_dim\n",
    "#             self.n_tasks = n_tasks\n",
    "#             self.ray_hidden_dim = ray_hidden_dim\n",
    "#             self.num_hidden_layer = num_hidden_layer\n",
    "#             self.last_activation = last_activation\n",
    "#             self.encoder = Encode(n_tasks, ray_hidden_dim)\n",
    "#             self.decoder = Decode(out_dim, n_tasks)\n",
    "#             self.output_layer =  nn.Linear(self.ray_hidden_dim, self.out_dim)\n",
    "#             self.attention = Attention(1,self.ray_hidden_dim)\n",
    "#       def forward(self, ray):\n",
    "#             x = self.encoder(ray)\n",
    "#             x =  self.attention(x)\n",
    "#             x = self.output_layer(x)\n",
    "#             x = x.permute(1,2,0)\n",
    "#             x = self.decoder(x)\n",
    "#             x = x.squeeze(2)\n",
    "#             if self.last_activation == 'relu':\n",
    "#                 x = F.relu(x)\n",
    "#             elif self.last_activation == 'sigmoid':\n",
    "#                 x = F.sigmoid(x)\n",
    "#             elif self.last_activation == 'softmax':\n",
    "#                 x = F.softmax(x)    \n",
    "#             else:\n",
    "#                 x = x\n",
    "#             return x\n",
    "class LeNetHyper_trans(nn.Module):\n",
    "    \"\"\"LeNet Hypernetwork\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_size: List[int],\n",
    "        ray_hidden_dim=100,\n",
    "        out_dim=10,\n",
    "        target_hidden_dim=50,\n",
    "        n_kernels=10,\n",
    "        n_conv_layers=2,\n",
    "        n_hidden=1,\n",
    "        n_tasks=2,\n",
    "        act_type = 'relu'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_conv_layers = n_conv_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_tasks = n_tasks\n",
    "        self.act_type = act_type\n",
    "        assert len(kernel_size) == n_conv_layers, (\n",
    "            \"kernel_size is list with same dim as number of \"\n",
    "            \"conv layers holding kernel size for each conv layer\"\n",
    "        )\n",
    "\n",
    "        # self.ray_mlp = nn.Sequential(\n",
    "        #     nn.Linear(2, ray_hidden_dim),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Linear(ray_hidden_dim, ray_hidden_dim),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Linear(ray_hidden_dim, ray_hidden_dim),\n",
    "        # )\n",
    "        #self.output_layer =  nn.Linear(ray_hidden_dim, n_kernels * kernel_size[0] * kernel_size[0])\n",
    "\n",
    "        if self.n_tasks == 2:\n",
    "            self.embedding_layer1 =  nn.Sequential(nn.Linear(1, ray_hidden_dim),nn.ReLU(inplace=True))\n",
    "            self.embedding_layer2 =  nn.Sequential(nn.Linear(1, ray_hidden_dim),nn.ReLU(inplace=True))\n",
    "        else:\n",
    "            self.embedding_layer1 =  nn.Sequential(nn.Linear(1, ray_hidden_dim),nn.ReLU(inplace=True))\n",
    "            self.embedding_layer2 =  nn.Sequential(nn.Linear(1, ray_hidden_dim),nn.ReLU(inplace=True))\n",
    "            self.embedding_layer3 =  nn.Sequential(nn.Linear(1, ray_hidden_dim),nn.ReLU(inplace=True))\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=ray_hidden_dim, num_heads=1) #MultiHeadAttention(d_model=ray_hidden_dim, n_head=2) #nn.MultiheadAttention(embed_dim=ray_hidden_dim, num_heads=2)\n",
    "        #self.pos_embedding = nn.Parameter(torch.randn(self.n_tasks, ray_hidden_dim))\n",
    "        self.ffn1 = nn.Linear(ray_hidden_dim,ray_hidden_dim)\n",
    "        self.ffn2 = nn.Linear(ray_hidden_dim,ray_hidden_dim)\n",
    "        \n",
    "        #self.ffn3 = nn.Linear(self.n_tasks,1)\n",
    "        self.output_layer = nn.Linear(ray_hidden_dim, ray_hidden_dim) #nn.Sequential(nn.Linear(ray_hidden_dim,ray_hidden_dim), nn.ReLU(inplace=True))  #nn.Linear(ray_hidden_dim, ray_hidden_dim)\n",
    "        \n",
    "        # self.encoder = Encode(n_tasks, ray_hidden_dim)\n",
    "        # self.decoder = Decode(out_dim, n_tasks)\n",
    "        # self.output_layer =  nn.Linear(ray_hidden_dim, ray_hidden_dim)\n",
    "        # self.attention = Attention(1,ray_hidden_dim)\n",
    "\n",
    "        self.conv_0_weights = nn.Linear(\n",
    "            ray_hidden_dim, n_kernels * kernel_size[0] * kernel_size[0]\n",
    "        )\n",
    "        self.conv_0_bias = nn.Linear(ray_hidden_dim, n_kernels)\n",
    "\n",
    "        for i in range(1, n_conv_layers):\n",
    "            # previous number of kernels\n",
    "            p = 2 ** (i - 1) * n_kernels\n",
    "            # current number of kernels\n",
    "            c = 2 ** i * n_kernels\n",
    "\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"conv_{i}_weights\",\n",
    "                nn.Linear(ray_hidden_dim, c * p * kernel_size[i] * kernel_size[i]),\n",
    "            )\n",
    "            setattr(self, f\"conv_{i}_bias\", nn.Linear(ray_hidden_dim, c))\n",
    "\n",
    "        latent = 25\n",
    "        self.hidden_0_weights = nn.Linear(\n",
    "            ray_hidden_dim, target_hidden_dim * 2 ** i * n_kernels * latent\n",
    "        )\n",
    "        self.hidden_0_bias = nn.Linear(ray_hidden_dim, target_hidden_dim)\n",
    "\n",
    "        for j in range(n_tasks):\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"task_{j}_weights\",\n",
    "                nn.Linear(ray_hidden_dim, target_hidden_dim * out_dim),\n",
    "            )\n",
    "            setattr(self, f\"task_{j}_bias\", nn.Linear(ray_hidden_dim, out_dim))\n",
    "\n",
    "    def shared_parameters(self):\n",
    "        return list([p for n, p in self.named_parameters() if \"task\" not in n])\n",
    "\n",
    "    def forward(self, ray):\n",
    "\n",
    "        if ray.shape[0] == 2:\n",
    "            x = torch.stack((self.embedding_layer1(ray[0].unsqueeze(0)),self.embedding_layer2(ray[1].unsqueeze(0))))\n",
    "        else:\n",
    "            x = torch.stack((self.embedding_layer1(ray[0].unsqueeze(0)),self.embedding_layer2(ray[1].unsqueeze(0)),self.embedding_layer3(ray[2].unsqueeze(0))))\n",
    "        #x += self.pos_embedding[:,:]\n",
    "        x_ = x\n",
    "        x = x.unsqueeze(1)\n",
    "        x,_ = self.attention(x,x,x)\n",
    "        x = x.squeeze(1)\n",
    "        x = x + x_\n",
    "        x_ = x\n",
    "        x = self.ffn1(x)\n",
    "        if self.act_type == 'relu':\n",
    "            x = F.relu(x) \n",
    "        else:\n",
    "            x = F.gelu(x)\n",
    "        x = self.ffn2(x)\n",
    "        x = x + x_\n",
    "        x = self.output_layer(x)\n",
    "        x = F.relu(x) \n",
    "        # print(x.shape)\n",
    "        features = torch.mean(x,dim=0)\n",
    "        # print(features.shape)\n",
    "        # x = self.encoder(ray)\n",
    "        # x =  self.attention(x)\n",
    "        # x = self.output_layer(x)\n",
    "        # x = F.relu(x) \n",
    "        # x = x.permute(1,0)\n",
    "        # x = self.decoder(x)\n",
    "        # #print(x.shape)\n",
    "        # features = x.squeeze(1)\n",
    "        \n",
    "        \n",
    "\n",
    "        out_dict = {}\n",
    "        layer_types = [\"conv\", \"hidden\", \"task\"]\n",
    "\n",
    "        for i in layer_types:\n",
    "            if i == \"conv\":\n",
    "                n_layers = self.n_conv_layers\n",
    "            elif i == \"hidden\":\n",
    "                n_layers = self.n_hidden\n",
    "            elif i == \"task\":\n",
    "                n_layers = self.n_tasks\n",
    "\n",
    "            for j in range(n_layers):\n",
    "                out_dict[f\"{i}{j}.weights\"] = getattr(self, f\"{i}_{j}_weights\")(\n",
    "                    features\n",
    "                )\n",
    "                out_dict[f\"{i}{j}.bias\"] = getattr(self, f\"{i}_{j}_bias\")(\n",
    "                    features\n",
    "                ).flatten()\n",
    "\n",
    "        return out_dict\n",
    "\n",
    "\n",
    "class LeNetTarget_trans(nn.Module):\n",
    "    \"\"\"LeNet target network\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernel_size,\n",
    "        n_kernels=10,\n",
    "        out_dim=10,\n",
    "        target_hidden_dim=50,\n",
    "        n_conv_layers=2,\n",
    "        n_tasks=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert len(kernel_size) == n_conv_layers, (\n",
    "            \"kernel_size is list with same dim as number of \"\n",
    "            \"conv layers holding kernel size for each conv layer\"\n",
    "        )\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_dim = out_dim\n",
    "        self.n_conv_layers = n_conv_layers\n",
    "        self.n_tasks = n_tasks\n",
    "        self.target_hidden_dim = target_hidden_dim\n",
    "\n",
    "    def forward(self, x, weights=None):\n",
    "        x = F.conv2d(\n",
    "            x,\n",
    "            weight=weights[\"conv0.weights\"].reshape(\n",
    "                self.n_kernels, 1, self.kernel_size[0], self.kernel_size[0]\n",
    "            ),\n",
    "            bias=weights[\"conv0.bias\"],\n",
    "            stride=1,\n",
    "        )\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        for i in range(1, self.n_conv_layers):\n",
    "            x = F.conv2d(\n",
    "                x,\n",
    "                weight=weights[f\"conv{i}.weights\"].reshape(\n",
    "                    int(2 ** i * self.n_kernels),\n",
    "                    int(2 ** (i - 1) * self.n_kernels),\n",
    "                    self.kernel_size[i],\n",
    "                    self.kernel_size[i],\n",
    "                ),\n",
    "                bias=weights[f\"conv{i}.bias\"],\n",
    "                stride=1,\n",
    "            )\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = F.linear(\n",
    "            x,\n",
    "            weight=weights[\"hidden0.weights\"].reshape(\n",
    "                self.target_hidden_dim, x.shape[-1]\n",
    "            ),\n",
    "            bias=weights[\"hidden0.bias\"],\n",
    "        )\n",
    "\n",
    "        logits = []\n",
    "        for j in range(self.n_tasks):\n",
    "            logits.append(\n",
    "                F.linear(\n",
    "                    x,\n",
    "                    weight=weights[f\"task{j}.weights\"].reshape(\n",
    "                        self.out_dim, self.target_hidden_dim\n",
    "                    ),\n",
    "                    bias=weights[f\"task{j}.bias\"],\n",
    "                )\n",
    "            )\n",
    "        return logits\n",
    "    def compute_l1_loss(self, w):\n",
    "        return torch.square(w).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57df920b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T16:13:52.230096Z",
     "iopub.status.busy": "2024-05-16T16:13:52.229790Z",
     "iopub.status.idle": "2024-05-16T16:13:52.266864Z",
     "shell.execute_reply": "2024-05-16T16:13:52.266039Z"
    },
    "papermill": {
     "duration": 0.049478,
     "end_time": "2024-05-16T16:13:52.269212",
     "exception": false,
     "start_time": "2024-05-16T16:13:52.219734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_hv(hypernet, targetnet, loader, rays, device):\n",
    "    hypernet.eval()\n",
    "    loss1 = nn.CrossEntropyLoss()\n",
    "    loss2 = nn.CrossEntropyLoss()\n",
    "    # num_samples = 0\n",
    "    results = defaultdict(list)\n",
    "    losses_all = []\n",
    "    \n",
    "    for ray in rays:\n",
    "        total = 0.0\n",
    "        task1_correct, task2_correct = 0.0, 0.0\n",
    "        l1, l2 = 0.0, 0.0\n",
    "        ray = torch.from_numpy(ray.astype(np.float32)).to(device)\n",
    "        ray /= ray.sum()\n",
    "        num_samples = 0\n",
    "        losses = np.zeros(2)\n",
    "        for batch in loader:\n",
    "            hypernet.zero_grad()\n",
    "\n",
    "            batch = (t.to(device) for t in batch)\n",
    "            img, ys = batch\n",
    "            bs = len(ys)\n",
    "            num_samples += bs\n",
    "            weights = hypernet(ray)\n",
    "            logit1, logit2 = targetnet(img, weights)\n",
    "\n",
    "            # loss\n",
    "            curr_l1 = loss1(logit1, ys[:, 0])\n",
    "            curr_l2 = loss2(logit2, ys[:, 1])\n",
    "            losses_batch = [curr_l1.detach().cpu().tolist(),curr_l2.detach().cpu().tolist()]\n",
    "            losses += bs * np.array(losses_batch)\n",
    "        losses /= num_samples\n",
    "        losses_all.append(losses)\n",
    "\n",
    "\n",
    "    return losses_all\n",
    "\n",
    "def train(\n",
    "    train_dt,\n",
    "    val_dt,\n",
    "    test_dt,\n",
    "    dataset,\n",
    "    path,\n",
    "    solver_type: str,\n",
    "    epochs: int,\n",
    "    hidden_dim: int,\n",
    "    model: str,\n",
    "    lr: float,\n",
    "    wd: float,\n",
    "    bs: int,\n",
    "    val_size: float,\n",
    "    n_rays: int,\n",
    "    alpha: float,\n",
    "    no_val_eval: bool,\n",
    "    out_dir: str,\n",
    "    device: torch.device,\n",
    "    eval_every: int,\n",
    "    model_type: str,\n",
    "    resume: bool,\n",
    ") -> None:\n",
    "    # ----\n",
    "    # Nets\n",
    "    # ----\n",
    "    if model == \"lenet\":\n",
    "        if model_type == 'mlp':\n",
    "            hnet = LeNetHyper([9, 5], ray_hidden_dim=hidden_dim)\n",
    "            if resume:\n",
    "                ckpt = torch.load(os.path.join(out_dir,'best_model_cheby_multi_'+str(dataset)+\"_\"+str(model_type)+'.pth'),map_location=device)\n",
    "                hnet.load_state_dict(ckpt['state_dicts'])\n",
    "            net = LeNetTarget([9, 5])\n",
    "        elif model_type == 'trans_relu':\n",
    "            hnet = LeNetHyper_trans([9, 5], ray_hidden_dim=hidden_dim,act_type='relu')\n",
    "            if resume:\n",
    "                ckpt = torch.load(os.path.join(out_dir,'best_model_cheby_multi_'+str(dataset)+\"_\"+str(model_type)+'_relu.pth'),map_location=device)\n",
    "                hnet.load_state_dict(ckpt['state_dicts'])\n",
    "            net = LeNetTarget_trans([9, 5])\n",
    "        else:\n",
    "            hnet = LeNetHyper_trans([9, 5], ray_hidden_dim=hidden_dim,act_type='gelu')\n",
    "            if resume:\n",
    "                ckpt = torch.load(os.path.join(out_dir,'best_model_cheby_multi_'+str(dataset)+\"_\"+str(model_type)+'_gelu.pth'),map_location=device)\n",
    "                hnet.load_state_dict(ckpt['state_dicts'])\n",
    "            net = LeNetTarget_trans([9, 5])\n",
    "\n",
    "    logging.info(f\"HN size: {count_parameters(hnet)}\")\n",
    "\n",
    "    hnet = hnet.to(device)\n",
    "    net = net.to(device)\n",
    "\n",
    "    # ---------\n",
    "    # Task loss\n",
    "    # ---------\n",
    "    loss1 = nn.CrossEntropyLoss()\n",
    "    loss2 = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(hnet.parameters(), lr=lr, weight_decay=wd)\n",
    "    if solver_type == \"epo\":\n",
    "        solver = EPOSolver(n_tasks=2, n_params=count_parameters(hnet))\n",
    "    elif solver_type == \"ls\":\n",
    "        # ls,cheby,utility\n",
    "        solver = LinearScalarizationSolver()\n",
    "    elif solver_type == \"cheby\":\n",
    "        # ls,cheby,utility\n",
    "        solver = ChebyshevBasedSolver(lower_bound = 0.1)\n",
    "    elif solver_type == \"utility\":\n",
    "        # ls,cheby,utility\n",
    "        solver = UtilityBasedSolver(upper_bound = 200.0)\n",
    "\n",
    "    # ----\n",
    "    # data\n",
    "    # ----\n",
    "    #assert val_size > 0, \"please use validation by providing val_size > 0\"\n",
    "#     train_loader, val_loader,test_loader = load_data(dataset,path)\n",
    "    min_angle = 0.1\n",
    "    max_angle = np.pi / 2 - 0.1\n",
    "    test_rays = circle_points(n_rays, min_angle=min_angle, max_angle=max_angle)\n",
    "\n",
    "    # ----------\n",
    "    # Train loop\n",
    "    # ----------\n",
    "    epoch_iter = trange(epochs)\n",
    "    best_hv_loss = -1 #-1\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in epoch_iter:\n",
    "        losses_epoch = []\n",
    "        loss_total = 0\n",
    "        l1_total = 0\n",
    "        l2_total = 0\n",
    "        count = 0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            hnet.train()\n",
    "            optimizer.zero_grad()\n",
    "            img, ys = batch\n",
    "            img = img.to(device)\n",
    "            ys = ys.to(device)\n",
    "\n",
    "            if alpha > 0:\n",
    "                ray = torch.from_numpy(\n",
    "                    np.random.dirichlet((alpha, alpha), 1).astype(np.float32).flatten()\n",
    "                ).to(device)\n",
    "            else:\n",
    "                alpha = torch.empty(\n",
    "                    1,\n",
    "                ).uniform_(0.0, 1.0)\n",
    "                ray = torch.tensor([alpha.item(), 1 - alpha.item()]).to(device)\n",
    "\n",
    "            weights = hnet(ray)\n",
    "            logit1, logit2 = net(img, weights)\n",
    "\n",
    "            l1 = loss1(logit1, ys[:, 0])\n",
    "            l2 = loss2(logit2, ys[:, 1])\n",
    "            #print(l1.shape)\n",
    "            losses = torch.stack((l1, l2))\n",
    "\n",
    "            ray = ray.squeeze(0)\n",
    "            loss = solver(losses, ray, list(hnet.parameters()))\n",
    "            loss.backward()\n",
    "            loss_total += loss.item()\n",
    "            l1_total += l1.item()\n",
    "            l2_total += l2.item()\n",
    "            count += 1\n",
    "            optimizer.step()\n",
    "#         loss_hv = evaluate_hv(\n",
    "#                     hypernet=hnet,\n",
    "#                     targetnet=net,\n",
    "#                     loader=val_loader,\n",
    "#                     rays=test_rays,\n",
    "#                     device=device,\n",
    "#                 )\n",
    "#         hv_loss = hypervolumn(np.array(loss_hv), type='loss', ref=np.ones(2) * 2)\n",
    "#         if hv_loss>best_hv_loss:\n",
    "#             best_hv_loss = hv_loss\n",
    "#             epoch_iter.set_description(\n",
    "#                 f\"Update best model, Epoch: {epoch:.0f}, Hv_eval: {hv_loss:.5f}, total mean loss: {loss_total/count:.5f}, mean l1: {l1/count:.5f}, mean l2: {l2/count:.5f}\"\n",
    "#             )\n",
    "#             # torch.save(hnet,os.path.join(out_dir,\"best_model_\"+str(solver_type)+\"_multi_\"+str(dataset)+\".pt\"))\n",
    "#             save_dict = {'state_dicts': hnet.state_dict()}\n",
    "#             if model_type == 'mlp':\n",
    "#                 torch.save(save_dict,\"best_model_\"+str(solver_type)+\"_multi_\"+str(dataset)+\"_\"+str(model_type)+\".pth\")\n",
    "#             elif model_type == 'trans_relu':\n",
    "#                 torch.save(save_dict,\"best_model_\"+str(solver_type)+\"_multi_\"+str(dataset)+\"_\"+str(model_type)+\".pth\")\n",
    "#             else:\n",
    "#                 torch.save(save_dict,\"best_model_\"+str(solver_type)+\"_multi_\"+str(dataset)+\"_\"+str(model_type)+\".pth\")\n",
    "#     ckpt = torch.load(\"/kaggle/working/best_model_\"+str(solver_type)+\"_multi_\"+str(dataset)+\"_\"+str(model_type)+\".pth\")\n",
    "#     hnet.load_state_dict(ckpt['state_dicts'])\n",
    "    loss_hv_test = evaluate_hv(\n",
    "                    hypernet=hnet,\n",
    "                    targetnet=net,\n",
    "                    loader=test_loader,\n",
    "                    rays=test_rays,\n",
    "                    device=device,\n",
    "                )\n",
    "    hv_loss_test = hypervolumn(np.array(loss_hv_test), type='loss', ref=np.ones(2) * 2)\n",
    "    save_dict = {'state_dicts': hnet.state_dict()}\n",
    "    torch.save(save_dict,\"last_model_multi_\"+str(dataset)+\"_\"+str(model_type)+\"_\"+str(hv_loss_test)+\".pth\")\n",
    "    print(\"HV_test: \",hv_loss_test)\n",
    "def load_data(dataset,data_path):\n",
    "    # LOAD DATASET\n",
    "    # ------------\n",
    "    # MultiMNIST: multi_mnist.pickle\n",
    "    if dataset == 'mnist':\n",
    "        path = os.path.join(data_path,'multi_mnist.pickle')\n",
    "\n",
    "    # MultiFashionMNIST: multi_fashion.pickle\n",
    "    if dataset == 'fashion':\n",
    "        path = os.path.join(data_path,'multi_fashion.pickle')\n",
    "\n",
    "    # Multi-(Fashion+MNIST): multi_fashion_and_mnist.pickle\n",
    "    if dataset == 'fashion_mnist':\n",
    "        path = os.path.join(data_path,'multi_fashion_and_mnist.pickle')\n",
    "\n",
    "    data = Dataset(path, val_size=0.1)\n",
    "    train_set, val_set, test_set = data.get_datasets()\n",
    "    batch_size = 256\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=batch_size,num_workers=2,\n",
    "        shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        dataset=val_set,\n",
    "        batch_size=batch_size,num_workers=2,\n",
    "        shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_set,\n",
    "        batch_size=batch_size,num_workers=2,\n",
    "        shuffle=False)\n",
    "    return train_loader,val_loader, test_loader\n",
    "def HPN_train(device,data_path,out_results,solver,batch_size,model_type,resume,train_loader, val_loader,test_loader):\n",
    "    set_seed(42)\n",
    "    set_logger()\n",
    "#     datasets = ['mnist','fashion','fashion_mnist']\n",
    "    if model_type == 'mlp':\n",
    "        hidden_dim = 256\n",
    "    else:\n",
    "        hidden_dim = 256\n",
    "#     for dataset in datasets:\n",
    "    print(\"Dataset: \",dataset)\n",
    "    print(\"Solver: \",solver)\n",
    "    start = time.time()\n",
    "    train(\n",
    "        train_dt = train_loader, \n",
    "        val_dt = val_loader,\n",
    "        test_dt = test_loader,\n",
    "        dataset = dataset,\n",
    "        path=data_path,\n",
    "        solver_type=solver,\n",
    "        epochs=150,\n",
    "        hidden_dim=hidden_dim,\n",
    "        model='lenet',\n",
    "        lr=1e-4,\n",
    "        wd=0.0,\n",
    "        bs=batch_size,\n",
    "        device=device,\n",
    "        eval_every=10,\n",
    "        no_val_eval=False,\n",
    "        val_size=0.1,\n",
    "        n_rays=25,\n",
    "        alpha=0.2,\n",
    "        out_dir=out_results,\n",
    "        model_type = model_type,\n",
    "        resume = resume,\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(\"Runtime training: \",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dacaf73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T16:13:52.290270Z",
     "iopub.status.busy": "2024-05-16T16:13:52.289892Z",
     "iopub.status.idle": "2024-05-16T17:51:41.601433Z",
     "shell.execute_reply": "2024-05-16T17:51:41.600066Z"
    },
    "papermill": {
     "duration": 5869.324339,
     "end_time": "2024-05-16T17:51:41.603616",
     "exception": false,
     "start_time": "2024-05-16T16:13:52.279277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver:  cheby\n",
      "Model type:  mlp\n",
      "Dataset:  mnist\n",
      "Solver:  cheby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [09:51<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HV_test:  2.8076614946943352\n",
      "Runtime training:  601.917332649231\n",
      "Model type:  trans_relu\n",
      "Dataset:  mnist\n",
      "Solver:  cheby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [11:06<00:00,  4.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HV_test:  2.839519136259348\n",
      "Runtime training:  677.5950446128845\n",
      "Model type:  trans_gelu\n",
      "Dataset:  mnist\n",
      "Solver:  cheby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [11:03<00:00,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HV_test:  2.8613751026427408\n",
      "Runtime training:  674.4925019741058\n",
      "Solver:  cheby\n",
      "Model type:  mlp\n",
      "Dataset:  fashion\n",
      "Solver:  cheby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [09:46<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HV_test:  2.1766518315232677\n",
      "Runtime training:  596.0419852733612\n",
      "Model type:  trans_relu\n",
      "Dataset:  fashion\n",
      "Solver:  cheby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [11:04<00:00,  4.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HV_test:  2.1901146940129506\n",
      "Runtime training:  675.7873957157135\n",
      "Model type:  trans_gelu\n",
      "Dataset:  fashion\n",
      "Solver:  cheby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [11:07<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HV_test:  2.1851968786301983\n",
      "Runtime training:  678.6776099205017\n",
      "Solver:  cheby\n",
      "Model type:  mlp\n",
      "Dataset:  fashion_mnist\n",
      "Solver:  cheby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [09:59<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HV_test:  2.8226038029601273\n",
      "Runtime training:  609.4356753826141\n",
      "Model type:  trans_relu\n",
      "Dataset:  fashion_mnist\n",
      "Solver:  cheby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [11:01<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HV_test:  2.830886944432782\n",
      "Runtime training:  673.0524175167084\n",
      "Model type:  trans_gelu\n",
      "Dataset:  fashion_mnist\n",
      "Solver:  cheby\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [11:06<00:00,  4.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HV_test:  2.755336216153385\n",
      "Runtime training:  677.2304589748383\n"
     ]
    }
   ],
   "source": [
    "model_types = [\"mlp\", \"trans_relu\", \"trans_gelu\"]\n",
    "datasets = ['mnist','fashion','fashion_mnist']\n",
    "resume = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_path = \"/kaggle/input/multi-mnist-fashion-fashmnist\"\n",
    "out_results = \"/kaggle/input/hyper-trans/Hyper_trans/MTL/experiments/Multi_task/MultiMNIST/outputs\"\n",
    "hpn_solver = \"epo\"\n",
    "batch_size = 256\n",
    "hpn_solvers = ['cheby']\n",
    "\n",
    "for dataset in datasets:\n",
    "    train_loader, val_loader,test_loader = load_data(dataset,data_path)\n",
    "    for hpn_solver in hpn_solvers:\n",
    "        print(\"Solver: \",hpn_solver)\n",
    "        for model_type in model_types:\n",
    "            print(\"Model type: \",model_type)\n",
    "            HPN_train(device,data_path,out_results,hpn_solver,batch_size,model_type,resume,train_loader, val_loader,test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71242d74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T17:51:41.826008Z",
     "iopub.status.busy": "2024-05-16T17:51:41.825644Z",
     "iopub.status.idle": "2024-05-16T17:51:41.842585Z",
     "shell.execute_reply": "2024-05-16T17:51:41.841792Z"
    },
    "papermill": {
     "duration": 0.130306,
     "end_time": "2024-05-16T17:51:41.844410",
     "exception": false,
     "start_time": "2024-05-16T17:51:41.714104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# def evaluate_hv(hypernet, targetnet, loader, rays, device):\n",
    "#     hypernet.eval()\n",
    "#     loss1 = nn.CrossEntropyLoss()\n",
    "#     loss2 = nn.CrossEntropyLoss()\n",
    "#     # num_samples = 0\n",
    "#     losses_all = []\n",
    "#     acc1, acc2 = [], []\n",
    "#     for ray in rays:\n",
    "#         total = 0.0\n",
    "#         task1_correct, task2_correct = 0.0, 0.0\n",
    "#         l1, l2 = 0.0, 0.0\n",
    "#         ray = torch.from_numpy(ray.astype(np.float32)).to(device)\n",
    "#         ray /= ray.sum()\n",
    "#         num_samples = 0\n",
    "#         losses = np.zeros(2)\n",
    "#         for batch in loader:\n",
    "#             hypernet.zero_grad()\n",
    "\n",
    "#             batch = (t.to(device) for t in batch)\n",
    "#             img, ys = batch\n",
    "#             bs = len(ys)\n",
    "#             num_samples += bs\n",
    "#             weights = hypernet(ray)\n",
    "#             logit1, logit2 = targetnet(img, weights)\n",
    "#             curr_l1 = loss1(logit1, ys[:, 0])\n",
    "#             curr_l2 = loss2(logit2, ys[:, 1])\n",
    "#             losses_batch = [curr_l1.detach().cpu().tolist(),curr_l2.detach().cpu().tolist()]\n",
    "#             losses += bs * np.array(losses_batch)\n",
    "#             # acc\n",
    "#             pred1 = logit1.data.max(1)[1]  # first column has actual prob.\n",
    "#             pred2 = logit2.data.max(1)[1]  # first column has actual prob.\n",
    "#             task1_correct += pred1.eq(ys[:, 0]).sum()\n",
    "#             task2_correct += pred2.eq(ys[:, 1]).sum()\n",
    "#         losses /= num_samples\n",
    "#         acc_1 = task1_correct/num_samples\n",
    "#         acc_2 = task2_correct/num_samples\n",
    "#         acc1.append(acc_1.tolist())\n",
    "#         acc2.append(acc_2.tolist())\n",
    "#         losses_all.append(losses.tolist())\n",
    "\n",
    "#     return losses_all, np.array(acc1), np.array(acc2)\n",
    "# def circle_points(K, min_angle=None, max_angle=None):\n",
    "#     # generate evenly distributed preference vector\n",
    "#     ang0 = 1e-6 if min_angle is None else min_angle\n",
    "#     ang1 = np.pi / 2 - ang0 if max_angle is None else max_angle\n",
    "#     angles = np.linspace(ang0, ang1, K, endpoint=True)\n",
    "#     x = np.cos(angles)\n",
    "#     y = np.sin(angles)\n",
    "#     return np.c_[x, y]\n",
    "# def phn_test(dataset,path_data,save_weights,device,mode):\n",
    "#     hnet = LeNetHyper([9, 5], ray_hidden_dim=265)\n",
    "#     hnet1 = LeNetHyper_trans([9, 5], ray_hidden_dim=256,act_type = 'relu')\n",
    "#     hnet2 = LeNetHyper_trans([9, 5], ray_hidden_dim=256,act_type = 'gelu')\n",
    "#     # hnet3 = LeNetHyper([9, 5], ray_hidden_dim=hidden_dim)\n",
    "#     # net = LeNetTarget([9, 5])\n",
    "\n",
    "#     # Load dataset\n",
    "#     # MultiMNIST: multi_mnist.pickle\n",
    "#     if dataset == 'mnist':\n",
    "#         path = os.path.join(path_data,'multi_mnist.pickle')\n",
    "\n",
    "#     # MultiFashionMNIST: multi_fashion.pickle\n",
    "#     if dataset == 'fashion':\n",
    "#         path = os.path.join(path_data,'multi_fashion.pickle')\n",
    "\n",
    "#     # Multi-(Fashion+MNIST): multi_fashion_and_mnist.pickle\n",
    "#     if dataset == 'fashion_mnist':\n",
    "#         path = os.path.join(path_data,'multi_fashion_and_mnist.pickle')\n",
    "\n",
    "#     # Load checkpoints\n",
    "#     ckpt = torch.load('/kaggle/working/best_model_ls_multi_'+str(dataset)+'_mlp.pth',map_location=device)\n",
    "#     hnet.load_state_dict(ckpt['state_dicts'])\n",
    "#     ckpt1 = torch.load('/kaggle/working/best_model_ls_multi_'+str(dataset)+'_trans_relu.pth',map_location=device)\n",
    "#     hnet1.load_state_dict(ckpt1['state_dicts'])\n",
    "#     ckpt2 = torch.load('/kaggle/working/best_model_ls_multi_'+str(dataset)+'_trans_gelu.pth',map_location=device)\n",
    "#     hnet2.load_state_dict(ckpt2['state_dicts'])\n",
    "#     # print(hnet2)\n",
    "#     hnet = hnet.to(device)\n",
    "#     hnet1 = hnet1.to(device)\n",
    "#     hnet2 = hnet2.to(device)\n",
    "#     fig = plt.figure()\n",
    "#     min_angle = 0.01\n",
    "#     max_angle = np.pi / 2 - min_angle\n",
    "#     num_rays = 25\n",
    "#     test_rays = circle_points(num_rays, min_angle=min_angle, max_angle=max_angle)\n",
    "#     bs = 256\n",
    "#     val_size = 0.1\n",
    "#     data = Dataset(path, val_size=0.1)\n",
    "#     train_set, val_set, test_set = data.get_datasets()\n",
    "#     batch_size = 256\n",
    "#     train_loader = torch.utils.data.DataLoader(\n",
    "#         dataset=train_set,\n",
    "#         batch_size=batch_size,num_workers=1,\n",
    "#         shuffle=True)\n",
    "#     val_loader = torch.utils.data.DataLoader(\n",
    "#         dataset=val_set,\n",
    "#         batch_size=batch_size,num_workers=1,\n",
    "#         shuffle=False)\n",
    "#     test_loader = torch.utils.data.DataLoader(\n",
    "#         dataset=test_set,\n",
    "#         batch_size=batch_size,num_workers=1,\n",
    "#         shuffle=False)\n",
    "#     loss_hv, acc_task_1_0, acc_task_2_0 = evaluate_hv(\n",
    "#                         hypernet=hnet,\n",
    "#                         targetnet=LeNetTarget([9, 5]),\n",
    "#                         loader=test_loader,\n",
    "#                         rays=test_rays,\n",
    "#                         device=device,\n",
    "#                     )\n",
    "#     loss_hv1, acc_task_1_1, acc_task_2_1 = evaluate_hv(\n",
    "#                         hypernet=hnet1,\n",
    "#                         targetnet=LeNetTarget_trans([9, 5]),\n",
    "#                         loader=test_loader,\n",
    "#                         rays=test_rays,\n",
    "#                         device=device,\n",
    "#                     )\n",
    "#     loss_hv2, acc_task_1_2, acc_task_2_2 = evaluate_hv(\n",
    "#                         hypernet=hnet2,\n",
    "#                         targetnet=LeNetTarget_trans([9, 5]),\n",
    "#                         loader=test_loader,\n",
    "#                         rays=test_rays,\n",
    "#                         device=device,\n",
    "#                     )\n",
    "#     # loss_hv3, acc_task_1_3, acc_task_2_3 = evaluate_hv(\n",
    "#     #                     hypernet=hnet3,\n",
    "#     #                     targetnet=net,\n",
    "#     #                     loader=test_loader,\n",
    "#     #                     rays=test_rays,\n",
    "#     #                     device=device,\n",
    "#     #                 )\n",
    "\n",
    "#     '''\n",
    "#         Multi Mnist\n",
    "#         x = [0.2,0.3,0.4,0.5]\n",
    "#         y = [0.2,0.4,0.6,0.8]\n",
    "#         plt.plot([0.2631959812361983,0.2631959812361983],[0.2,0.8],ls='-.',c='black',label='Single task')\n",
    "#         plt.plot([0.2,0.5],[0.33708666510219815,0.33708666510219815],ls='-.',c='black')\n",
    "#     '''\n",
    "#     '''\n",
    "#         Multi Fashion\n",
    "#         x = [0.4,0.6,0.8,1.0]\n",
    "#         y = [0.4,0.6,0.8,1.0]\n",
    "#         plt.plot([0.4857283249686036,0.4857283249686036],[0.4,1],ls='-.',c='black',label='Single task')\n",
    "#         plt.plot([0.4,1],[0.5331778043433081,0.5331778043433081],ls='-.',c='black')\n",
    "#     '''\n",
    "#     '''\n",
    "#         Multi Fashion Mnist\n",
    "#         x = [0.1,0.4,0.7,1.0]\n",
    "#         y = [0.4,0.6,0.8,1.0]\n",
    "#         plt.plot([0.16867540993645222,0.16867540993645222],[0.4,1],ls='-.',c='black',label = 'Single-task')\n",
    "#         plt.plot([0.1,1],[0.44227917699874203,0.44227917699874203],ls='-.',c='black')\n",
    "#     '''\n",
    "#     '''\n",
    "#         # Accuracy MNIST\n",
    "#         x = [0.82,0.84,0.88,0.92]\n",
    "#         y = [0.78,0.82,0.86,0.9]\n",
    "#         plt.plot([0.91,0.91],[0.78,0.9],ls='-.',label = 'Single-task',c='black')\n",
    "#         plt.plot([0.82,0.92],[0.885,0.885],ls='-.',c='black')   \n",
    "#     '''\n",
    "#     '''\n",
    "#         # Accuracy Fashion\n",
    "#         x = [0.68,0.73,0.78,0.83]\n",
    "#         y = [0.6,0.68,0.76,0.84]\n",
    "#         plt.plot([0.82,0.82],[0.6,0.84],ls='-.',label = 'Single-task',c='black')\n",
    "#         plt.plot([0.68,0.83],[0.80,0.80],ls='-.',c='black')\n",
    "#     '''\n",
    "#     '''\n",
    "#         # Accuracy Fashion + MNIST\n",
    "#         x = [0.6,0.72,0.84,0.96]\n",
    "#         y = [0.59,0.68,0.77,0.86]\n",
    "#         plt.plot([0.94,0.94],[0.59,0.86],ls='-.',label = 'Single-task',c='black')\n",
    "#         plt.plot([0.6,0.96],[0.84,0.84],ls='-.',c='black')\n",
    "#     '''\n",
    "#     if mode == \"loss\":\n",
    "#         if dataset == 'mnist':\n",
    "#             loss_hv = np.array(loss_hv)\n",
    "#             loss_hv1 = np.array(loss_hv1)\n",
    "#             loss_hv2 = np.array(loss_hv2)\n",
    "#             # loss_hv3 = np.array(loss_hv3)\n",
    "#             x_ = [loss_hv[0, 0],loss_hv[4, 0],loss_hv[9, 0],loss_hv[14, 0],loss_hv[19, 0],loss_hv[24, 0]]\n",
    "#             y_ = [loss_hv[0, 1],loss_hv[4, 1],loss_hv[9, 1],loss_hv[14, 1],loss_hv[19, 1],loss_hv[24, 1]]\n",
    "#             #plt.plot(loss_hv[:, 0], loss_hv[:, 1],label = 'HPN-LS',marker='*',linestyle = '-')\n",
    "#             plt.plot(loss_hv[:, 0], loss_hv[:, 1],linestyle = '-',label = 'MLP')\n",
    "#             plt.scatter(x_, y_,marker='*')\n",
    "#             x1_ = [loss_hv1[0, 0],loss_hv1[4, 0],loss_hv1[9, 0],loss_hv1[14, 0],loss_hv1[19, 0],loss_hv1[24, 0]]\n",
    "#             y1_ = [loss_hv1[0, 1],loss_hv1[4, 1],loss_hv1[9, 1],loss_hv1[14, 1],loss_hv1[19, 1],loss_hv1[24, 1]]\n",
    "#             plt.plot(loss_hv1[:, 0], loss_hv1[:, 1],linestyle = '-.',label = 'Trans_ReLU')\n",
    "#             plt.scatter(x1_, y1_,marker='o')\n",
    "#             x2_ = [loss_hv2[0, 0],loss_hv2[4, 0],loss_hv2[9, 0],loss_hv2[14, 0],loss_hv2[19, 0],loss_hv2[24, 0]]\n",
    "#             y2_ = [loss_hv2[0, 1],loss_hv2[4, 1],loss_hv2[9, 1],loss_hv2[14, 1],loss_hv2[19, 1],loss_hv2[24, 1]]\n",
    "#             plt.plot(loss_hv2[:, 0], loss_hv2[:, 1],linestyle = ':',label = 'Trans_GeLU')\n",
    "#             plt.scatter(x2_, y2_,marker='x')\n",
    "#             # x3_ = [loss_hv3[0, 0],loss_hv3[4, 0],loss_hv3[9, 0],loss_hv3[14, 0],loss_hv3[19, 0],loss_hv3[24, 0]]\n",
    "#             # y3_ = [loss_hv3[0, 1],loss_hv3[4, 1],loss_hv3[9, 1],loss_hv3[14, 1],loss_hv3[19, 1],loss_hv3[24, 1]]\n",
    "#             # plt.plot(loss_hv3[:, 0], loss_hv3[:, 1],linestyle = '--')\n",
    "#             # plt.scatter(x3_, y3_,marker='v',label = 'PHN-EPO')\n",
    "#             x = [0.2,0.3,0.4,0.5]\n",
    "#             y = [0.2,0.35,0.5,0.65]\n",
    "#             plt.plot([0.2631959812361983,0.2631959812361983],[0.2,0.65],ls='-.',c='black',label='Single task')\n",
    "#             plt.plot([0.2,0.5],[0.33708666510219815,0.33708666510219815],ls='-.',c='black')\n",
    "#             plt.xlabel(\"Loss CE task left\",fontsize=18)\n",
    "#             plt.ylabel(\"Loss CE task right\",fontsize=18)\n",
    "#             plt.xticks(x)\n",
    "#             plt.yticks(y)\n",
    "#             plt.legend(fontsize=18)\n",
    "#             plt.tight_layout()\n",
    "#             plt.savefig('test_multi_'+str(dataset)+'.jpg')\n",
    "#             #plt.savefig('test_multi_'+str(dataset)+'.pdf')\n",
    "#         elif dataset == 'fashion':\n",
    "#             loss_hv = np.array(loss_hv)\n",
    "#             loss_hv1 = np.array(loss_hv1)\n",
    "#             loss_hv2 = np.array(loss_hv2)\n",
    "# #             loss_hv3 = np.array(loss_hv3)\n",
    "#             x_ = [loss_hv[0, 0],loss_hv[4, 0],loss_hv[9, 0],loss_hv[14, 0],loss_hv[19, 0],loss_hv[24, 0]]\n",
    "#             y_ = [loss_hv[0, 1],loss_hv[4, 1],loss_hv[9, 1],loss_hv[14, 1],loss_hv[19, 1],loss_hv[24, 1]]\n",
    "#             #plt.plot(loss_hv[:, 0], loss_hv[:, 1],label = 'HPN-LS',marker='*',linestyle = '-')\n",
    "#             plt.plot(loss_hv[:, 0], loss_hv[:, 1],linestyle = '-',label = 'MLP')\n",
    "#             plt.scatter(x_, y_,marker='*')\n",
    "#             x1_ = [loss_hv1[0, 0],loss_hv1[4, 0],loss_hv1[9, 0],loss_hv1[14, 0],loss_hv1[19, 0],loss_hv1[24, 0]]\n",
    "#             y1_ = [loss_hv1[0, 1],loss_hv1[4, 1],loss_hv1[9, 1],loss_hv1[14, 1],loss_hv1[19, 1],loss_hv1[24, 1]]\n",
    "#             plt.plot(loss_hv1[:, 0], loss_hv1[:, 1],linestyle = '-.',label = 'Transfomer')\n",
    "#             plt.scatter(x1_, y1_,marker='o')\n",
    "#             x2_ = [loss_hv2[0, 0],loss_hv2[4, 0],loss_hv2[9, 0],loss_hv2[14, 0],loss_hv2[19, 0],loss_hv2[24, 0]]\n",
    "#             y2_ = [loss_hv2[0, 1],loss_hv2[4, 1],loss_hv2[9, 1],loss_hv2[14, 1],loss_hv2[19, 1],loss_hv2[24, 1]]\n",
    "#             plt.plot(loss_hv2[:, 0], loss_hv2[:, 1],linestyle = ':',label = 'Trans_GeLU')\n",
    "#             plt.scatter(x2_, y2_,marker='x')\n",
    "# #             x3_ = [loss_hv3[0, 0],loss_hv3[4, 0],loss_hv3[9, 0],loss_hv3[14, 0],loss_hv3[19, 0],loss_hv3[24, 0]]\n",
    "# #             y3_ = [loss_hv3[0, 1],loss_hv3[4, 1],loss_hv3[9, 1],loss_hv3[14, 1],loss_hv3[19, 1],loss_hv3[24, 1]]\n",
    "# #             plt.plot(loss_hv3[:, 0], loss_hv3[:, 1],linestyle = '--')\n",
    "# #             plt.scatter(x3_, y3_,marker='v',label = 'PHN-EPO')\n",
    "#             x = [0.4,0.6,0.8,1.0]\n",
    "#             y = [0.4,0.6,0.8,1.0]\n",
    "#             plt.plot([0.4857283249686036,0.4857283249686036],[0.4,1],ls='-.',c='black',label='Single task')\n",
    "#             plt.plot([0.4,1],[0.5331778043433081,0.5331778043433081],ls='-.',c='black')\n",
    "#             plt.xlabel(\"Loss CE task left\",fontsize=18)\n",
    "#             plt.ylabel(\"Loss CE task right\",fontsize=18)\n",
    "#             plt.xticks(x)\n",
    "#             plt.yticks(y)\n",
    "#             plt.legend(fontsize=18)\n",
    "#             plt.tight_layout()\n",
    "#             plt.savefig('test_multi_'+str(dataset)+'.jpg')\n",
    "#         elif dataset == 'fashion_mnist':\n",
    "#             loss_hv = np.array(loss_hv)\n",
    "#             loss_hv1 = np.array(loss_hv1)\n",
    "#             loss_hv2 = np.array(loss_hv2)\n",
    "# #             loss_hv3 = np.array(loss_hv3)\n",
    "#             x_ = [loss_hv[0, 0],loss_hv[4, 0],loss_hv[9, 0],loss_hv[14, 0],loss_hv[19, 0],loss_hv[24, 0]]\n",
    "#             y_ = [loss_hv[0, 1],loss_hv[4, 1],loss_hv[9, 1],loss_hv[14, 1],loss_hv[19, 1],loss_hv[24, 1]]\n",
    "#             #plt.plot(loss_hv[:, 0], loss_hv[:, 1],label = 'HPN-LS',marker='*',linestyle = '-')\n",
    "#             plt.plot(loss_hv[:, 0], loss_hv[:, 1],linestyle = '-',label = 'MLP')\n",
    "#             plt.scatter(x_, y_,marker='*')\n",
    "#             x1_ = [loss_hv1[0, 0],loss_hv1[4, 0],loss_hv1[9, 0],loss_hv1[14, 0],loss_hv1[19, 0],loss_hv1[24, 0]]\n",
    "#             y1_ = [loss_hv1[0, 1],loss_hv1[4, 1],loss_hv1[9, 1],loss_hv1[14, 1],loss_hv1[19, 1],loss_hv1[24, 1]]\n",
    "#             plt.plot(loss_hv1[:, 0], loss_hv1[:, 1],linestyle = '-.')\n",
    "#             plt.scatter(x1_, y1_,marker='o',linestyle = '-.',label = 'Trans_ReLU')\n",
    "#             x2_ = [loss_hv2[0, 0],loss_hv2[4, 0],loss_hv2[9, 0],loss_hv2[14, 0],loss_hv2[19, 0],loss_hv2[24, 0]]\n",
    "#             y2_ = [loss_hv2[0, 1],loss_hv2[4, 1],loss_hv2[9, 1],loss_hv2[14, 1],loss_hv2[19, 1],loss_hv2[24, 1]]\n",
    "#             plt.plot(loss_hv2[:, 0], loss_hv2[:, 1],linestyle = ':',label = 'Trans_GeLU')\n",
    "#             plt.scatter(x2_, y2_,marker='x')\n",
    "# #             x3_ = [loss_hv3[0, 0],loss_hv3[4, 0],loss_hv3[9, 0],loss_hv3[14, 0],loss_hv3[19, 0],loss_hv3[24, 0]]\n",
    "# #             y3_ = [loss_hv3[0, 1],loss_hv3[4, 1],loss_hv3[9, 1],loss_hv3[14, 1],loss_hv3[19, 1],loss_hv3[24, 1]]\n",
    "# #             plt.plot(loss_hv3[:, 0], loss_hv3[:, 1],linestyle = '--')\n",
    "# #             plt.scatter(x3_, y3_,marker='v',label = 'PHN-EPO')\n",
    "#             x = [0.1,0.4,0.7,1.0]\n",
    "#             y = [0.4,0.6,0.8,1.0]\n",
    "#             plt.plot([0.16867540993645222,0.16867540993645222],[0.4,1],ls='-.',c='black',label = 'Single-task')\n",
    "#             plt.plot([0.1,1],[0.44227917699874203,0.44227917699874203],ls='-.',c='black')\n",
    "#             plt.xlabel(\"Loss CE task left\",fontsize=18)\n",
    "#             plt.ylabel(\"Loss CE task right\",fontsize=18)\n",
    "#             plt.xticks(x)\n",
    "#             plt.yticks(y)\n",
    "#             plt.legend(fontsize=18)\n",
    "#             plt.tight_layout()\n",
    "#             plt.savefig('test_multi_'+str(dataset)+'.jpg')\n",
    "#         print(\"HV MLP: \",hypervolumn(np.array(loss_hv), type='loss', ref=np.ones(2) * 2))\n",
    "#         print(\"HV Trans_ReLU: \",hypervolumn(np.array(loss_hv1), type='loss', ref=np.ones(2) * 2))\n",
    "#         print(\"HV Trans_GeLU: \",hypervolumn(np.array(loss_hv2), type='loss', ref=np.ones(2) * 2))\n",
    "#         # print(\"HV PHN-EPO: \",hypervolumn(np.array(loss_hv3), type='loss', ref=np.ones(2) * 2))\n",
    "# datasets = ['mnist','fashion','fashion_mnist']\n",
    "# path_data = '/kaggle/input/multi-mnist-fashion-fashmnist'\n",
    "# save_weights = './save_weights'\n",
    "# device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# mode = 'loss'\n",
    "# for dataset in datasets:\n",
    "#     phn_test(dataset,path_data,save_weights,device,mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca6b856",
   "metadata": {
    "papermill": {
     "duration": 0.10824,
     "end_time": "2024-05-16T17:51:42.061950",
     "exception": false,
     "start_time": "2024-05-16T17:51:41.953710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1978673,
     "sourceId": 3266280,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3781992,
     "sourceId": 6543054,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3782008,
     "sourceId": 6543088,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5938.471986,
   "end_time": "2024-05-16T17:51:43.606391",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-16T16:12:45.134405",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
